{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabete= pd.read_csv(\"data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabete[\"Glucose\"]= diabete[\"Glucose\"].replace({0: np.nan}).fillna(diabete[\"Glucose\"].mean())\n",
    "diabete[\"BloodPressure\"]= diabete[\"BloodPressure\"].replace({0: np.nan}).fillna(diabete[\"BloodPressure\"].mean())\n",
    "diabete[\"SkinThickness\"]= diabete[\"SkinThickness\"].replace({0: np.nan}).fillna(diabete[\"SkinThickness\"].mean())\n",
    "diabete[\"Insulin\"]= diabete[\"Insulin\"].replace({0: np.nan}).fillna(diabete[\"Insulin\"].mean())\n",
    "diabete[\"BMI\"]= diabete[\"BMI\"].replace({0: np.nan}).fillna(diabete[\"BMI\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness     Insulin   BMI  \\\n",
       "0            6    148.0           72.0      35.000000   79.799479  33.6   \n",
       "1            1     85.0           66.0      29.000000   79.799479  26.6   \n",
       "2            8    183.0           64.0      20.536458   79.799479  23.3   \n",
       "3            1     89.0           66.0      23.000000   94.000000  28.1   \n",
       "4            0    137.0           40.0      35.000000  168.000000  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "X= diabete[features]\n",
    "y= diabete[\"Outcome\"].ravel()\n",
    "m,n = X.shape\n",
    "number_of_samples = y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalization(X):\n",
    "    \"\"\"\n",
    "    Normalizes the features in X. returns a normalized version of X where\n",
    "    the mean value of each feature is 0 and the standard deviation\n",
    "    is 1. This is often a good preprocessing step to do when working with\n",
    "    learning algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_normalized : array_like\n",
    "        The normalized dataset of shape (m x n).\n",
    "    mean: array_like\n",
    "        Mean of every column\n",
    "    standard_deviation : array_like\n",
    "        Standard Deviation of every column\n",
    "    \"\"\"\n",
    "    standard_deviation = np.std(X, axis= 0)\n",
    "    mean = np.mean(X, axis= 0)\n",
    "    X_normalized = (X - mean)/ standard_deviation\n",
    "    \n",
    "    return X_normalized, mean, standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X, mean_X, standard_deviation_X = feature_normalization(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add intercept term to martix X\n",
    "X = np.concatenate([np.ones((len(X), 1)), X], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function given the input z.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        The input to the sigmoid function. This can be a 1-D vector \n",
    "        or a 2-D matrix. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    g : array_like\n",
    "        The computed sigmoid function. g has the same shape as z, since\n",
    "        the sigmoid is computed element-wise on z.\n",
    "    \"\"\"\n",
    "    # convert every element to numpy array (matrix, vector or scalar)\n",
    "    z = np.array(z)\n",
    "    # create free space as size as input \n",
    "    g = np.zeros(z.shape)\n",
    "    # computing sigmoid function\n",
    "    g = (1 / (1 + np.exp(-z)))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(theta, X, y):\n",
    "    \"\"\"\n",
    "    Compute cost_function for logistic regression. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        The parameters for logistic regression. This a vector\n",
    "        of shape (n+1, ).\n",
    "    \n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1) where m is the total number\n",
    "        of data points and n is the number of features. We assume the \n",
    "        intercept has already been added to the input.\n",
    "    \n",
    "    y : arra_like\n",
    "        Labels for the input. This is a vector of shape (m, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed value for the cost function. \n",
    "    \"\"\"\n",
    "    # Initialize some useful values like number_of_samples, J and grad\n",
    "    number_of_samples = y.size\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "    # hypothesis function\n",
    "    h = sigmoid(np.dot(X, theta.T))\n",
    "    # implementation of J\n",
    "    J = (1/number_of_samples) * (np.sum(np.dot(-y, np.log(h))) - np.dot((1-y), (np.log(1-h))))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(theta, X, y):\n",
    "    \"\"\"\n",
    "    Compute gradient_descent for logistic regression. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        The parameters for logistic regression. This a vector\n",
    "        of shape (n+1, ).\n",
    "    \n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n+1) where m is the total number\n",
    "        of data points and n is the number of features. We assume the \n",
    "        intercept has already been added to the input.\n",
    "    \n",
    "    y : arra_like\n",
    "        Labels for the input. This is a vector of shape (m, ).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    grad : array_like\n",
    "        A vector of shape (n+1, ) which is the gradient of the cost\n",
    "        function with respect to theta, at the current values of theta.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values like number_of_samples, J and grad\n",
    "    grad = np.zeros(theta.shape)\n",
    "    # hypothesis function\n",
    "    h = sigmoid(np.dot(X, theta.T))\n",
    "    # implementation of gradient\n",
    "    grad = (1/number_of_samples) * np.dot((h - y), X)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial values\n",
    "options= {\"maxiter\": 400, \"disp\": True}\n",
    "initial_theta = np.zeros(n+1)\n",
    "# optimize cost_function with method= \"TNC\". for more information check below link\n",
    "# https://docs.scipy.org/doc/scipy/reference/optimize.minimize-tnc.html#optimize-minimize-tnc\n",
    "# if you define cost_function and gradient_descent in one function, then you need to change below options as below\n",
    "# the unified function that contains cost and grad will not need to pass another function on\n",
    "# jac= on optimize.minimize function and only True value is enough, but when we have separate functions\n",
    "# cost_function is out main function and jac= gradient_descent work same as past\n",
    "result= optimize.minimize(cost_function, initial_theta, (X, y), jac= gradient_descent, method= \"TNC\", options= options)\n",
    "# put optimizied values in variables\n",
    "# fun property is minimum value and x is optimized theta\n",
    "cost_value= result.fun\n",
    "theta_optimized= result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression.\n",
    "    Computes the predictions for X using a threshold at 0.5 \n",
    "    (i.e., if sigmoid(theta.T*x) >= 0.5, predict 1)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        Parameters for logistic regression. A vecotor of shape (n+1, ).\n",
    "    \n",
    "    X : array_like\n",
    "        The data to use for computing predictions. The rows is the number \n",
    "        of points to compute predictions, and columns is the number of\n",
    "        features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p : array_like\n",
    "        Predictions and 0 or 1 for each row in X. \n",
    "    \"\"\"\n",
    "    number_of_samples= X.shape[0] # number of exmaple \n",
    "    predicted= np.zeros(number_of_samples)\n",
    "    \n",
    "    predicted = np.round(sigmoid(np.dot(X, theta.T))) # round using a threshold at 0.5\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    \"\"\"\n",
    "    check prediction accuracy with comparison between predict and actual value\n",
    "    if two parameter(predicted and actual value) are equal diff will be 0 and \n",
    "    otherwise will be 1. count of nonzero devided by len of diff is errors. 1 minus \n",
    "    error is our prediction accuracy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : array_like\n",
    "        Predicted values that output of predict function.\n",
    "    \n",
    "    y : array_like\n",
    "        Actual value of data, (Labels)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    number : float\n",
    "        model accuracy percentage\n",
    "    \"\"\"\n",
    "    diff = y_pred - y\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy(Numpy Equal Checking): 78.12 %\n",
      "Expected accuracy (approx): 89.00 %\n",
      "\n",
      "Train Accuracy(XNOR Logic): 78.12 %\n",
      "Expected accuracy (approx): 89.00 %\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on our training set\n",
    "model_predicted = predict(theta_optimized, X)\n",
    "print(\"Train Accuracy(Numpy Equal Checking): {:.2f} %\".format(np.mean(model_predicted == y) * 100))\n",
    "print(\"Expected accuracy (approx): 89.00 %\\n\")\n",
    "# Compute accuracy with XNOR logic\n",
    "model_predicted = predict(theta_optimized, X)\n",
    "print(\"Train Accuracy(XNOR Logic): {:.2f} %\".format(np.mean(np.invert(np.logical_xor(model_predicted, y))) * 100))\n",
    "print(\"Expected accuracy (approx): 89.00 %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
